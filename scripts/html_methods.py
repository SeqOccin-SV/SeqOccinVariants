#!/usr/bin/env python


import pandas as pd
from collections import defaultdict
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as Ticker
import os
from pretty_html_table import build_table
import seaborn as sns
import re


def parse_stat_file(stat_file):
    """Parsing a file generated by samtools stats for a pbmm2 output bam."""
    rawdata = defaultdict(list)
    with open(stat_file) as fin:
        for line in fin:
            if line.startswith('#'):
                continue
            fields = line.rstrip().split("\t")
            rawdata[fields[0]].append("\t".join(fields[1:]))
    return rawdata


def parse_SN(data):
    """Get all SN data from the samtools stats file.
    
    The lines starting with SN in a samtools stats output file
    contain global information such as the number of sequences,
    mapped reads of average sequence length.

    """
    parsed_data = defaultdict()
    for line in data:
        sections = line.split("\t")
        field = sections[0].strip()[:-1]
        field = field.replace(" ", "_")
        value = float(sections[1].strip())
        parsed_data[field] = value
    return parsed_data


def parse_COV(data):
    """Get all the COV (coverage) data from the samtools stats file."""
    values = []
    counts = []
    for line in data:
        fields = line.split("\t")
        values.append(int(fields[1]))
        counts.append(int(fields[2]))
    x = np.array(values)
    c = np.array(counts)
    return {'counts': c, 'values': x}


def cov_df(file):
    """Get the COV data from a samtools stats file and store it in a DataFrame."""
    data = parse_stat_file(file)
    cov = parse_COV(data['COV'])
    df = pd.DataFrame(cov)
    return df


def draw_ax(ax, df, columnX, columnY, title='Distribution', xlabel = 'x', ylabel = 'y'):
    """Build axes to draw a single barplot.
    
    Args:
        ax (Axes): Axe on which to draw the barplot.
        df (DataFrame): DataFrame from which to build the barplot.
        columnX (str): DataFrame key corresponding to the X axis.
        columnY (str): DataFrame key corresponding to the Y axis.

    """
    ax.bar(df[columnX],df[columnY])
    ax.set_title(title, fontsize=18)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    

def draw_depth_distribution(ax, df, title = "Depth distribution") :
    """Draw a single barplot."""
    draw_ax(ax, df[df['values']<100], 'values', 'counts', title, 'values', 'counts')


def get_title(filename, ext = "") :
    """Define a title for plots based on input file name.

    Args:
        filename (str): Name of the input file.
        ext (str): extention to add to the created title name.

    """
    filename = filename.split('/')[-1]
    CCS = re.compile(r"(.*)-(CCS.*)")
    CLR = re.compile(r"(.*)-(CLR.*)")
    ONT = re.compile(r"(.*)-(ONT.*)")
    mCCS = re.match(CCS, filename)
    mCLR = re.match(CLR, filename)
    mONT = re.match(ONT, filename)
    if mCCS is not None :
        return mCCS.group(1) + " " + ext
    if mCLR is not None :
        return mCLR.group(1) + " " + ext
    if mONT is not None :
        return mONT.group(1) + " " + ext
    return (filename.split('.')[0] + " " + ext)


def add_in_dic(dic, file) :
    """Add a individual file to the dictionary used to plot the depth distribution."""
    ax = 'ax' + str(len(dic['ax']) + 1)
    dic['ax'].append(ax)
    dic[ax] = (file, cov_df(file))


def build_dic_depth_distribution(files) :
    """Creat and fill the dictionary used to plot the depth distribution."""
    dic = {'ax' : []}
    for f in files :
        add_in_dic(dic, f)
    return dic


def build_png(files, png) :
    """Draw and arrange a barplot for each input individual."""
    dic = build_dic_depth_distribution(files)
    tab = dic['ax']
    fig, (tab) = plt.subplots(len(dic['ax']),1, constrained_layout=True, 
          figsize=(12,3*len(dic['ax'])))
    if len(dic['ax']) == 1 :
        title = get_title(dic[dic['ax'][0]][0], "depth distribution")
        draw_depth_distribution(tab, dic[dic['ax'][0]][1], title)
    else :
        for i in range(len(dic['ax'])) :
            title = get_title(dic[dic['ax'][i]][0], "depth distribution")
            draw_depth_distribution(tab[i], dic[dic['ax'][i]][1], title)
    plt.savefig(png)


def html_header() :
    """Creat a string containing the header for the html file."""
    return """ <!DOCTYPE html>
    <html>
    <head>
    <title>Page Title</title>
    </head>
    <body>
    <style>
        div {
            text-align: center;
            margin: 50px 50px
        }
        table.center {
            margin-left: auto;
            margin-right: auto;
        }
    </style>
    <div>
    """
   

def html_tail() :
    """Create a string containing the ending for the html file."""
    return """</div>
    </body>
    </html> 
    """
    

def write_html(file, body) :
    """Write the html body between the header and the tail."""
    with open(file, 'w') as f :
        f.write(html_header())
        f.write(body)
        f.write(html_tail())


def html_graph_output(png, title, text = "", subtext = "") :
    """Input graph in html file using base64 text representation of a image.
    
    Using base64 text allows the html file to be moved without having to take
    into acount the path to the png files.

    """
    header = "<h2>" + title + "</h2>\n"
    info = "<p>" + text + "</p>\n"
    # img = '<img src="' + str(png) + '">' + "\n"
    img = '<img width="900" src="data:image/png;base64,' + png + '">\n'
    under_img = "<p>" + subtext + "</p>\n<br><br>"
    return header + info + img + under_img


def html_build_table(dic, title = "Structural variant stats", text = "", subtext = "") :
    """Build an HTML table from a dictionary."""
    body = "<h2>" + title + "</h2>\n"
    body += "<p>" + text + "</p>\n"
    df = pd.DataFrame(dic)
    table = build_table(df, 'blue_light', font_size = "25px")
    new_table = table[0:28] + 'center' + table[37:]
    body += new_table
    body += "<p>" + subtext + "</p>\n"
    body += "<br><br>"
    return body


def parse_vcf_for_table(files) :
    """Parse sevral files containing extracted data from vcf files in a dictionary.

    info :
        building the input file : 
        bcftools query -f "%ID\n" name-pbsv.vcf.gz | 
        cut -f2 -d'.' | sort | uniq -c > sv_stats.txt

    Args:
        files (list) : list of file names.
    
    Return:
        dictionary: number of variants for each type, for each individual.

    """
    grouped = {'name' : [], 'BND' : [], 'DEL' : [], 'INS' : [], 'INV' : [], 'SPLIT' : []}
    indel = []
    for file in files :
        dic = {}
        indel.append(get_title(file))
        with open(file, 'r') as f :
            for line in f :
                l = line.split()
                if len(l) > 1 :
                    dic[l[1]] = l[0]
        for i in grouped.keys() :
            if i in dic.keys() :
                grouped[i].append(dic[i])
            else :
                grouped[i].append(0)
    grouped['name'] = indel
    return grouped


def get_files_from_file(all_files) :
    """Creat a lisr of file names from an intput file.
    
    Args:
        all_files (str): File listing file names.

    Returns:
        list: List of files listed in the input file.

    """
    files = []
    with open(all_files, 'r') as f :
        for sub_files in f :
            try :
                with open(sub_files[:-1], 'r') :
                    files.append(sub_files[:-1])
            except IOError :
                print(sub_files + " not found or can't be read.")
    return files


def file_to_single_string(file) :
    """Build a single string from the content of a base64 text file."""
    txt = ""
    with open(file) as f :
        for l in f :
            txt += l
    return txt


def png_to_base64txt(png, txt = None) :
    """Converts png file to base64 single sting for html imbeded image."""
    if txt is None :
        txt = '.'.join(png.split('.')[:-1]) + ".txt"
#    txt = png
    base64 = "base64 " + png + " > " + txt
    os.system(base64)
    return file_to_single_string(txt)


def color_scaling(column_length) :
    """Creat a color scaling based on the number of individuals for plotting."""
    colors = []
    nbG = 0
    nbR = 0
    if column_length%2 != 0 :
        nbG = int(column_length/2)+1
        nbR = int(column_length/2)
    else :
        nbG = nbR = int(column_length/2)
    r = 0
    g = 0
    b = 1
    incr = 1/column_length
    for i in range(0,nbG) :
        colors.append((r,g,b))
        r += incr
        b -= incr
        g += incr*2
    for i in range(0,nbR) :
        r += incr
        b -= incr
        g -= incr*2
        colors.append((r,g,b))
    return colors


def hist_draw(df, ax, col) :
    """Draw histograms for each variant type.
    
    Args:
        df (DataFrame): Variant type DataFrame.
        ax (Axes): Axe on which to draw the plot.
        col (str): DataFrame colmn to draw.

    """
    ax.bar(df['name'], df[col], color = color_scaling(len(df['name'])))
    max_cap = int(max(df[col]) + max(df[col])/10)
    if max_cap > 0 :
        ax.set_ylim([0, max_cap])
    ax.set_title(col, fontsize=18)
    ax.xaxis.set_major_locator(Ticker.FixedLocator([x+0.5 for x in list(range(0, len(df['name'])))]))
    ax.set_xticklabels(df['name'], rotation=45, ha='right')


def pbsv_graphs(dic, png = 'pbsv_stats.png') :
    """Draw png barplot of the different variant types."""
    df = pd.DataFrame(dic)
    data = ['BND', 'DEL', 'INS', 'INV', 'SPLIT']
    for d in data :
        df[d] = df[d].astype(int)    
    df['SV'] = df[['BND', 'DEL', 'INS', 'INV', 'SPLIT']].sum(axis = 1)
    data.append('SV')
    axs = ['ax1', 'ax2', 'ax3', 'ax4', 'ax5', 'ax6']
    fig, ((axs[0], axs[1]), (axs[2], axs[3]), (axs[4], axs[5])) = plt.subplots(3,2, constrained_layout=True, figsize=(12,10))
    for i in range(0, len(data)) :
        hist_draw(df, axs[i], data[i])
    # plt.tight_layout()
    plt.savefig(png)


def parse_longshot_for_table(files) :
    """Parse longshot stats files in dictionary.

    Info:
        This funtion also works on deepvariant stats files.

    """
    grouped = {'name' : [], 'SNPs' : [], 'transitions' : [], 'transvertions' : [], 'ts/tv' : []}
    for file in files :
        with open(file, 'r') as f :
            for line in f :
                l = line.split()
                if l[0] == 'TSTV' :
                    grouped['name'].append(get_title(file))
                    grouped['SNPs'].append(int(l[2]) + int(l[3]))
                    grouped['transitions'].append(int(l[2]))
                    grouped['transvertions'].append(int(l[3]))
                    grouped['ts/tv'].append(float(l[4]))
    return grouped


def draw_variantsizes(file, ax, title = 'Insertion and Deletion size distribution') :
    """Draw the size distribution of INS and DEL for an individual."""
    df = pd.read_csv(file, sep='\t', dtype={'chrom' : str})
    df_INS = df[df['svtype'] == 'INS'][['svtype', 'size']]
    df_DEL = df[df['svtype'] == 'DEL'][['svtype', 'size']]
    # rearange df_INS DataFrame
    df_INS['occurence'] = df_INS.groupby('size')['size'].transform('size')
    df_INS.drop_duplicates(inplace=True)
    df_INS.sort_values('size', inplace=True)
    # rearange df_DEL DataFrame
    df_DEL['occurence'] = df_DEL.groupby('size')['size'].transform('size')
    df_DEL.drop_duplicates(inplace=True)
    df_DEL['size'] = df_DEL['size'].map(lambda occurence: occurence * -1)
    df_DEL.sort_values('size', inplace=True)
    # fig, ax = plt.subplots(1,1, constrained_layout=True, figsize=(12,3))
    df_INS.plot(x='size', y='occurence', ax=ax, label='INS')
    df_DEL.plot(x='size', y='occurence', ax=ax, label='DEL')
    ax.set_title(title, fontsize=18)
    ax.set_xlabel('size')
    ax.set_ylabel('count')
    # ax.set_xscale('symlog') can be used for symetric log scale
    ax.set_xscale('log')
    ax.legend()


def draw_variantsizes_png(files, png) :
    """Draw png INS DEL size distribution for each individual."""
    axs = []
    for i in range(len(files)) :
        axs.append("ax" + str(i))
    fig, axs = plt.subplots(len(files),1, constrained_layout=True, figsize=(12,3*len(files)))
    if len(files) == 1 :
        draw_variantsizes(files[0], axs, title = get_title(files[0], "INS & DEL size distribution"))
    else :
        for i in range(len(files)) :
            draw_variantsizes(files[i], axs[i], title = get_title(files[i], "INS & DEL size distribution"))
    plt.savefig(png)


def png_naming(file_name) :
    """Define png file name based on input file name."""
    return "stats/" + file_name.split('/')[-1] + ".png"


def mapped_reads(seq_cout, indx) :
    """Build a dictionary for mapped reads inforamtion."""
    sc = {}
    with open(seq_cout, 'r') as file :
        for line in file :
            if line.split()[0] not in sc.keys() :
                sc[line.split()[0]] = {'reads' : [int(line.split()[1])], 'length' : [int(line.split()[2])]}
            else :
                sc[line.split()[0]]['reads'].append(int(line.split()[1]))
                sc[line.split()[0]]['length'].append(int(line.split()[2]))
    bam_fofn = {}
    for k in sc.keys() :
        sc[k]['reads'] = sum(sc[k]['reads'])
        sc[k]['length'] = sum(sc[k]['length'])
    with open(indx, 'r') as file :
        for line in file :
            bam_fofn[line.split()[0]] = line.split()[1]
    for k in bam_fofn.keys() :
        bam_fofn[k] = (sc[bam_fofn[k]]['reads'], sc[bam_fofn[k]]['length'])
    return bam_fofn


def get_mapped_reads(file) :
    """Extract information about mapped reads from a stats file."""
    info = {'reads' : 0, 'total' : 0, 'cigar' : 0}
    with open(file, 'r') as f:
        for line in f :
            if "reads mapped:" in line :
                info['reads'] = int(line.split()[3])
            if "total length:" in line :
                info['total'] = int(line.split()[3])
            if "bases mapped (cigar):" in line :
                info['cigar'] = int(line.split()[4])
    return info


def mapped_coverage_html(dic) :
    """Build dictionary of reads data for the html output."""
    mapped = {'name' : [], 'reads' : [], 'mapped' : [], '% mapped' : [], '% mapped bases' : []}
    for k in dic.keys() :
        mapped['name'].append(get_title(k))
        mapped['reads'].append(dic[k][0])
        mreads = get_mapped_reads(k)
        mapped['mapped'].append(mreads['reads'])
        mapped['% mapped'].append((mreads['reads']/dic[k][0])*100)
        # mapped['% mapped bases'].append(mreads['total']/dic[k][1]*100)
        mapped['% mapped bases'].append(mreads['cigar']/dic[k][1]*100)
    return mapped


def write_full_html(bam_stats_files, pbsv_stats_files, variantsizes_files, snp_stats_files, number, index, html = "stats/pipeline_output.html") :
    """Write an html report file based on stats files.

    Stat files are generated by the pacBio_variant snakemake pipeline.
    
    Args:
        bam_stats_files (str): File listing samtools stats outputs.
        pbsv_stats_files (str): File listing bcftools query rearanged outputs.
        variantsizes_files (str): File listing bcftools query rearanged outputs.
        snp_stats_files (str): File listing longshot or deepvariant stats outputs.
        number (str): File containing the number of sequences and total length.
        index (str): File linking stats files to individuals.
        html (str): Html output file name.

    """
    sns.set_theme()
    body = "<h1>PacBio Variants pipeline stats</h1>\n<br><br>"
    # mapping data
    mapped = mapped_coverage_html(mapped_reads(number, index))
    body += html_build_table(mapped, 'Mapped reads')
    # Build pbmm2 depth graphs
    bam = get_files_from_file(bam_stats_files) 
    png = png_naming(bam_stats_files)
    build_png(bam, png)
    txt = png_to_base64txt(png)
    body += html_graph_output(txt, 'Samples pbmm2')
    # get pbsv vcf file data for variant table
    pbsv = get_files_from_file(pbsv_stats_files)
    dic = parse_vcf_for_table(pbsv)
    body += html_build_table(dic, 'pbsv structural variant stats')
    png = png_naming(pbsv_stats_files)
    pbsv_graphs(dic, png)
    txt = png_to_base64txt(png)
    body += html_graph_output(txt, 'pbsv stats barplots')
    # pbsv insertion & deletion size distribution
    variantsizes = get_files_from_file(variantsizes_files)
    png = png_naming(variantsizes_files)
    draw_variantsizes_png(variantsizes, png)
    txt = png_to_base64txt(png)
    body += html_graph_output(txt, 'Insertion Deletion stats')
    # SNP with longshot or deepvariant
    snp = get_files_from_file(snp_stats_files)
    dic_ls = parse_longshot_for_table(snp)
    if snp_stats_files == "stats/SNP_longshot.stats" :
        body += html_build_table(dic_ls, 'longshot SNP stats')
    if snp_stats_files == "stats/SNP_dv.stats" :
        body += html_build_table(dic_ls, 'deepvariant SNP stats')

    write_html(html, body)



if __name__ == "__main__" :

    import argparse

    parser = argparse.ArgumentParser(description = "Creat html from costum stat file lists.")
    parser.add_argument("-b", "--bam", help = "bam stats file list file.", required = True)
    parser.add_argument("-p", "--pbsv", help = "pbsv stats file list file.", required = True)
    parser.add_argument("-v", "--variants", help = "variants stats file list file.", required = True)
    parser.add_argument("-s", "--snp", help = "snp stats file list file.", required = True)
    parser.add_argument("-i", "--index", help = "index linking fofn file to bam.stats file.", required = True)
    parser.add_argument("-n", "--number", help = "number of sequences in each imput file.", required = True)
    parser.add_argument("-t", "--html", help = "html output file.", required = False)
    
    args = parser.parse_args()
    
    html = "stats/pipeline_output.html"
    
    if args.html is not None :
        html = args.html
    
    write_full_html(args.bam, args.pbsv, args.variants, args.snp, args.number, args.index, args.html)




